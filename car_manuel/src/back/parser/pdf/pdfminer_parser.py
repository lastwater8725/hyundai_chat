import os
import json
import re
from glob import glob
from pdfminer.high_level import extract_pages
from pdfminer.layout import LTTextBoxHorizontal, LAParams 

input_dir = "./data/car_manual_data"
output_dir = "./data/parsed/pdfminer"

# ê¸€ì ê°ì§€, íƒ€ì… ë¶„ë¥˜, ê²½ê³  ë¶„ë¥˜
def parse_pdf(pdf_path):
    laparams = LAParams()
    pages_data = []
    
    list_pattern = r"^\s*(\d+[\.\)]|[\-\â€¢\â—‹])\s+"
    warning_keywords = ["ì£¼ì˜", "ê²½ê³ ", "WARNING", "CAUTION", "âš ï¸"]
    
    for page_num, page_layout in enumerate(extract_pages(pdf_path, laparams= laparams), start=1):
        blocks = []
        for element in page_layout:
            if isinstance(element, LTTextBoxHorizontal):
                text = element.get_text().strip()
                if not text:
                    continue
                
                # ê¸€ìí¬ê¸° ê³„ì‚°
                font_size = []
                for text_line in element:
                    for char in text_line:
                        if hasattr(char, 'size'):
                            font_size.append(char.size)
                avg_font_size = sum(font_size) / len(font_size) if font_size else 0
                
                # ê¸°ë³¸ íƒ€ì… (title, subtitle, paragraph)
                if avg_font_size > 15:
                    block_type = "title"
                elif avg_font_size > 12:
                    block_type = "subtitle"
                else:
                    block_type = "paragraph"
            
                # ê²½ê³  ë¶„ë¥˜
                if any(keyword in text for keyword in warning_keywords):
                    block_type = "warning"
                    
                # ë©€í‹°ë¼ì¸ ë¦¬ìŠ¤íŠ¸ ë¶„ë¥˜ example: 1.1.1, 1) 2)
                split_lines = text.split("\n")
                for line in split_lines:
                    line = line.strip()
                    if not line:
                        continue
                    
                    current_block_type = block_type
                    
                    if re.match(list_pattern, line):
                        current_block_type = "list"
                        
                    blocks.append({
                        "type": current_block_type,
                        "bbox": [element.x0, element.y0, element.x1, element.y1],  
                        "text": line
                    })
                    
                    
        # ğŸ”¥ warning ë¸”ë¡ ë³‘í•© ì¶”ê°€
        merged_blocks = []
        prev_block = None
        for block in blocks:
            if prev_block and block["type"] == "warning" and prev_block["type"] == "warning" and block["bbox"] == prev_block["bbox"]:
                prev_block["text"] += " " + block["text"]
            else:
                merged_blocks.append(block)
                prev_block = block

        pages_data.append({
            "page": page_num,
            "blocks": merged_blocks
        })
        
    return pages_data
                    
def save_json(data, file_name, output_dir):
    os.makedirs(output_dir, exist_ok=True)
    output_path = os.path.join(output_dir, file_name)
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    print(f"ì €ì¥ ì™„ë£Œ: {output_path}")
                                    

def read_pdf(input_dir, output_dir):
    pdf_files = glob(os.path.join(input_dir, "*.pdf"))
    print(f"PDF íŒŒì¼ ê°œìˆ˜: {len(pdf_files)}") 
    
    for pdf_file in pdf_files:
        base_name = os.path.splitext(os.path.basename(pdf_file))[0]
        output_name = f"{base_name}_pdfminer.json"
        parsed = parse_pdf(pdf_file)
        save_json(parsed, output_name, output_dir)

if __name__== "__main__":
    read_pdf(input_dir, output_dir) 