from fastapi import APIRouter, File, UploadFile, Form, HTTPException
from pydantic import BaseModel
from typing import List
from .modules import load_db
from .hyperclova_client import generate_question_from_image
import traceback

# âœ… main.pyì—ì„œ embedding, llm_chain ì£¼ì… ì˜ˆì •
embedding = None
llm_chain = None

router = APIRouter()

# ğŸ”– ì‘ë‹µ ë°ì´í„° ëª¨ë¸ ì •ì˜
class SourceInfo(BaseModel):
    page: int
    model: str

class ImageQueryResponse(BaseModel):
    generated_question: str
    answer: str
    sources: List[SourceInfo]

# ì´ë¯¸ì§€ ê¸°ë°˜ ì§ˆë¬¸ ë° ì‘ë‹µ ì²˜ë¦¬
@router.post("/image-query", response_model=ImageQueryResponse)
async def image_query(
    image: UploadFile = File(...),
    model: str = Form(...)
):
    model_key_map = {
        "ì•„ë°˜ë–¼": "avante", "ì‹¼íƒ€í˜": "santafe", "íˆ¬ì‹¼": "tucson",
        "ìºìŠ¤í¼": "casper", "ìŠ¤íƒ€ë¦¬ì•„": "staria", "ê·¸ëœì €": "grandeur",
        "ì†Œë‚˜íƒ€": "sonata", "ì•„ì´ì˜¤ë‹‰9": "ionic9", "ì•„ì´ì˜¤ë‹‰5": "ionic5"
    }

    model_key = model_key_map.get(model)
    if not model_key:
        raise HTTPException(status_code=400, detail="ì§€ì›í•˜ì§€ ì•ŠëŠ” ì°¨ëŸ‰ ëª¨ë¸ì…ë‹ˆë‹¤.")

    # 1ï¸ì´ë¯¸ì§€ì—ì„œ ì§ˆë¬¸ ìƒì„±
    try:
        image_bytes = await image.read()
        generated_query = generate_question_from_image(image_bytes)
    except Exception as e:
        print(traceback.format_exc())
        raise HTTPException(status_code=500, detail=f"ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")

    # 2ï¸ë¬¸ì„œ ê²€ìƒ‰
    try:
        db = load_db(model_key, embedding)
        docs = db.similarity_search(generated_query, k=10)
    except Exception as e:
        print(traceback.format_exc())
        raise HTTPException(status_code=500, detail="FAISS ì¸ë±ìŠ¤ ë¡œë”© ë˜ëŠ” ê²€ìƒ‰ ì‹¤íŒ¨")

    # 3ï¸ê´€ë ¨ ë¬¸ì„œ í•„í„°ë§
    filtered_docs = [doc for doc in docs if doc.metadata.get("model") == model]
    selected_docs = filtered_docs[:3] if filtered_docs else docs[:3]

    if not selected_docs:
        return ImageQueryResponse(
            generated_question=generated_query,
            answer="í•´ë‹¹ ì°¨ëŸ‰ì— ëŒ€í•œ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.",
            sources=[]
        )

    # 4ë¬¸ë§¥ êµ¬ì„±
    context_blocks = []
    model_count = {}

    for doc in selected_docs:
        doc_model = doc.metadata.get("model", "ë¯¸ì§€ì •")
        pages = doc.metadata.get("pages", ["?"])
        model_count[doc_model] = model_count.get(doc_model, 0) + 1
        citation = f"[page {pages[0]} / model: {doc_model}]"
        context_blocks.append(f"{citation}\n{doc.page_content}")

    context = "\n\n".join(context_blocks)
    most_common_model = max(model_count, key=model_count.get)

    # 5ï¸âƒ£ LLM ì¶”ë¡ 
    result = llm_chain.invoke({
        "query": generated_query,
        "context": context,
        "model": most_common_model
    })

    answer_text = result.split("ë‹µë³€:")[-1].strip() if "ë‹µë³€:" in result else result.strip()
    sources = [
        {"page": doc.metadata.get("pages", ["?"])[0], "model": doc.metadata.get("model", "ë¯¸ì§€ì •")}
        for doc in selected_docs
    ]

    return ImageQueryResponse(
        generated_question=generated_query,
        answer=answer_text,
        sources=sources
    )
